# åŸºäºtimmåº“çš„PyTorché€šç”¨å›¾åƒåˆ†ç±»æ¡†æ¶

<div align="center">

![Python Version](https://img.shields.io/badge/python-3.6+-blue.svg)
![PyTorch Version](https://img.shields.io/badge/pytorch-1.2.0+-orange.svg)
![License](https://img.shields.io/badge/license-MIT-green.svg)

ä¸€ä¸ªåŠŸèƒ½å®Œå–„çš„å›¾åƒåˆ†ç±»æ·±åº¦å­¦ä¹ æ¡†æ¶,æ”¯æŒtimmä¸­å¤šç§ä¸»æµCNNå’ŒTransformeræ¶æ„,æä¾›å®Œæ•´çš„è®­ç»ƒã€è¯„ä¼°å’Œæ¨ç†æµç¨‹ã€‚

[ç‰¹æ€§](#-ç‰¹æ€§) â€¢ [å¿«é€Ÿå¼€å§‹](#-å¿«é€Ÿå¼€å§‹) â€¢ [æ¨¡å‹æ”¯æŒ](#-æ”¯æŒçš„æ¨¡å‹) â€¢ [è¯„ä¼°æŒ‡æ ‡](#-è¯„ä¼°æŒ‡æ ‡) â€¢ [æ–‡æ¡£](#-è¯¦ç»†æ–‡æ¡£)

</div>

---

## ğŸ“‹ ç›®å½•

- [ç‰¹æ€§](#-ç‰¹æ€§)
- [ç¯å¢ƒè¦æ±‚](#-ç¯å¢ƒè¦æ±‚)
- [å®‰è£…](#-å®‰è£…)
- [å¿«é€Ÿå¼€å§‹](#-å¿«é€Ÿå¼€å§‹)
- [æ”¯æŒçš„æ¨¡å‹](#-æ”¯æŒçš„æ¨¡å‹)
- [é¡¹ç›®ç»“æ„](#-é¡¹ç›®ç»“æ„)
- [è¯¦ç»†æ–‡æ¡£](#-è¯¦ç»†æ–‡æ¡£)
- [è¯„ä¼°æŒ‡æ ‡](#-è¯„ä¼°æŒ‡æ ‡)
- [å¸¸è§é—®é¢˜](#-å¸¸è§é—®é¢˜)
- [æ›´æ–°æ—¥å¿—](#-æ›´æ–°æ—¥å¿—)
- [è®¸å¯è¯](#-è®¸å¯è¯)

---

## âœ¨ ç‰¹æ€§

- ğŸš€ **å¤šæ¨¡å‹æ”¯æŒ**: é›†æˆ15+ç§ä¸»æµæ¶æ„(ResNetã€VGGã€EfficientNetã€ViTã€Swin Transformerç­‰)
- ğŸ¯ **å®Œæ•´çš„è®­ç»ƒæµç¨‹**: ä¸¤é˜¶æ®µè®­ç»ƒç­–ç•¥(å†»ç»“+è§£å†»),è‡ªé€‚åº”å­¦ä¹ ç‡è°ƒæ•´
- ğŸ“Š **ä¸°å¯Œçš„è¯„ä¼°æŒ‡æ ‡**: å‡†ç¡®ç‡ã€Precisionã€Recallã€F1ã€AUCã€ROCæ›²çº¿ã€æ··æ·†çŸ©é˜µç­‰
- ğŸ”„ **ç±»åˆ«ä¸å¹³è¡¡å¤„ç†**: æ”¯æŒFocal Lossã€ç±»åˆ«åŠ æƒã€å¹³è¡¡é‡‡æ ·ç­‰ç­–ç•¥
- ğŸ“ˆ **å¯è§†åŒ–åˆ†æ**: è‡ªåŠ¨ç”Ÿæˆè®­ç»ƒæ›²çº¿ã€ROC/PRæ›²çº¿ã€æ··æ·†çŸ©é˜µç­‰å¯è§†åŒ–æŠ¥å‘Š
- ğŸ’» **åˆ†å¸ƒå¼è®­ç»ƒ**: æ”¯æŒDPå’ŒDDPå¤šGPUè®­ç»ƒæ¨¡å¼
- ğŸ¨ **æ•°æ®å¢å¼º**: å†…ç½®å¤šç§æ•°æ®å¢å¼ºç­–ç•¥,æå‡æ¨¡å‹æ³›åŒ–èƒ½åŠ›
- ğŸ“¦ **å³æ’å³ç”¨**: ç®€æ´çš„é…ç½®,æœ€å°‘3ä¸ªå‚æ•°å³å¯å¼€å§‹è®­ç»ƒ

---

## ğŸ”§ ç¯å¢ƒè¦æ±‚

- **Python**: 3.6+ (æ¨è3.8+)
- **PyTorch**: 1.2.0+ (æ¨è2.0+)
- **CUDA**: å¯é€‰,ç”¨äºGPUåŠ é€Ÿè®­ç»ƒ
- **æ“ä½œç³»ç»Ÿ**: Windows / Linux / macOS

---

## ğŸ“¦ å®‰è£…

### 1. å…‹éš†ä»“åº“

```bash
git clone https://github.com/yourusername/classification-pytorch.git
cd classification-pytorch
```

### 2. åˆ›å»ºè™šæ‹Ÿç¯å¢ƒ(æ¨è)

```bash
# ä½¿ç”¨conda
conda create -n cls python=3.8
conda activate cls

# æˆ–ä½¿ç”¨venv
python -m venv venv
source venv/bin/activate  # Linux/macOS
venv\Scripts\activate     # Windows
```

### 3. å®‰è£…ä¾èµ–

```bash
# æ ‡å‡†å®‰è£…
pip install -r requirements.txt

# å¦‚æœä½¿ç”¨è¾ƒæ–°çš„Pythonç‰ˆæœ¬(3.11+),ä¾èµ–ä¼šè‡ªåŠ¨é€‚é…
```

**æ ¸å¿ƒä¾èµ–:**
- `torch>=1.2.0` - PyTorchæ·±åº¦å­¦ä¹ æ¡†æ¶
- `torchvision>=0.4.0` - å›¾åƒå¤„ç†å·¥å…·
- `timm` - é¢„è®­ç»ƒæ¨¡å‹åº“(1000+æ¨¡å‹)
- `scikit-learn>=1.0.0` - è¯„ä¼°æŒ‡æ ‡è®¡ç®—
- `matplotlib>=3.1.2` - å¯è§†åŒ–
- `opencv-python>=4.1.2` - å›¾åƒå¤„ç†
- `pandas>=2.0.0` - æ•°æ®å¤„ç†
- `seaborn>=0.13.0` - é«˜çº§å¯è§†åŒ–

---

## ğŸš€ å¿«é€Ÿå¼€å§‹

### 1. å‡†å¤‡æ•°æ®é›†

æŒ‰ä»¥ä¸‹ç»“æ„ç»„ç»‡ä½ çš„æ•°æ®:

```
datasets/
â”œâ”€â”€ train/
â”‚   â”œâ”€â”€ class_0/
â”‚   â”‚   â”œâ”€â”€ img1.jpg
â”‚   â”‚   â””â”€â”€ img2.jpg
â”‚   â”œâ”€â”€ class_1/
â”‚   â””â”€â”€ class_2/
â””â”€â”€ test/
    â”œâ”€â”€ class_0/
    â”œâ”€â”€ class_1/
    â””â”€â”€ class_2/
```

### 2. ç”Ÿæˆæ ‡æ³¨æ–‡ä»¶

```bash
python txt_annotation.py
```

è¿™å°†ç”Ÿæˆ `cls_train.txt` å’Œ `cls_test.txt` æ ‡æ³¨æ–‡ä»¶,ä»¥åŠ `model_data/cls_classes.txt` ç±»åˆ«æ–‡ä»¶ã€‚

### 3. é…ç½®æ¨¡å‹å‚æ•°

ç¼–è¾‘ `train.py` æˆ– `train_trimm.py` ä¸­çš„å…³é”®å‚æ•°:

```python
# æ¨¡å‹é€‰æ‹©
backbone = 'inception_resnet_v2'  # å¯é€‰: resnet50, efficientnet_b0, vit_b_16ç­‰
input_shape = [299, 299]          # è¾“å…¥å›¾åƒå°ºå¯¸

# è®­ç»ƒå‚æ•°
Init_Epoch = 0
Freeze_Epoch = 50                 # å†»ç»“è®­ç»ƒè½®æ•°
Epoch = 300                       # æ€»è®­ç»ƒè½®æ•°
batch_size = 32
```

### 4. å¼€å§‹è®­ç»ƒ

```bash
# æ ‡å‡†è®­ç»ƒ
python train.py

# ä½¿ç”¨timmæ¨¡å‹åº“è®­ç»ƒ(æ¨è)
python train_trimm.py

# å¤šGPUè®­ç»ƒ(Linux)
CUDA_VISIBLE_DEVICES=0,1 python train.py
```

### 5. æ¨¡å‹è¯„ä¼°

```bash
python eval.py
```

è¯„ä¼°ç»“æœå°†ä¿å­˜åœ¨ `metrics_out/` ç›®å½•,åŒ…æ‹¬:
- ğŸ“Š æ··æ·†çŸ©é˜µ (`confusion_matrix.png`)
- ğŸ“ˆ ROC/PRæ›²çº¿ (`roc_curves.png`, `pr_curves.png`)
- ğŸ“‰ æŒ‡æ ‡å¯¹æ¯”å›¾ (`metrics_comparison_chart.png`)
- ğŸ“ å®Œæ•´åˆ†ç±»æŠ¥å‘Š (`classification_report.txt`)

### 6. æ¨¡å‹æ¨ç†

```bash
# å•å¼ å›¾ç‰‡é¢„æµ‹
python predict.py
# ç„¶åè¾“å…¥å›¾ç‰‡è·¯å¾„

# æ‰¹é‡é¢„æµ‹
python Predict_All_Precision_Calculation.py
```

---

## ğŸ—ï¸ æ”¯æŒçš„æ¨¡å‹

### ç»å…¸CNNæ¶æ„

| æ¨¡å‹ | Input Size | å‚æ•°é‡ | ç‰¹ç‚¹ |
|------|-----------|--------|------|
| **ResNet** (18/34/50/101/152) | 224Ã—224 | 11M-60M | æ®‹å·®è¿æ¥,æ·±å±‚ç½‘ç»œè®­ç»ƒç¨³å®š |
| **VGG** (11/13/16 + BNå˜ä½“) | 224Ã—224 | 128M-143M | ç»å…¸æ¶æ„,ç‰¹å¾æå–å¼º |
| **MobileNetV2** | 224Ã—224 | 3.5M | è½»é‡çº§,é€‚åˆç§»åŠ¨ç«¯éƒ¨ç½² |
| **DenseNet** (121/161/169/201) | 224Ã—224 | 7M-44M | å¯†é›†è¿æ¥,å‚æ•°æ•ˆç‡é«˜ |
| **EfficientNet** (B0-B7) | 224Ã—224+ | 5M-66M | SOTAå‡†ç¡®ç‡,æ•ˆç‡ä¼˜åŒ– |
| **Inceptionç³»åˆ—** | 299Ã—299 | 23M-56M | å¤šå°ºåº¦ç‰¹å¾èåˆ |
| **Xception** | 299Ã—299 | 23M | æ·±åº¦å¯åˆ†ç¦»å·ç§¯ |
| **InceptionResNetV2** | 299Ã—299 | 56M | Inception+æ®‹å·®,é«˜å‡†ç¡®ç‡ |

### Transformeræ¶æ„

| æ¨¡å‹ | Input Size | å‚æ•°é‡ | ç‰¹ç‚¹ |
|------|-----------|--------|------|
| **ViT-B/16** | 224Ã—224 | 86M | Vision Transformer,å¤§æ•°æ®é›†è¡¨ç°ä¼˜å¼‚ |
| **Swin Transformer** (Tiny/Small/Base) | 224Ã—224 | 28M-88M | å±‚æ¬¡åŒ–Transformer,å¹³è¡¡æ€§èƒ½å’Œæ•ˆç‡ |

### ä½¿ç”¨timmåº“æ‰©å±•

é€šè¿‡ `train_trimm.py` å¯ä»¥ä½¿ç”¨ **1000+ç§é¢„è®­ç»ƒæ¨¡å‹**:

```python
# ç¤ºä¾‹:ä½¿ç”¨EfficientNet-B3
model = timm.create_model('efficientnet_b3', pretrained=True, num_classes=num_classes)
```

---

## ğŸ“ é¡¹ç›®ç»“æ„

```
classification-pytorch/
â”œâ”€â”€ datasets/              # æ•°æ®é›†ç›®å½•
â”‚   â”œâ”€â”€ train/            # è®­ç»ƒé›†
â”‚   â””â”€â”€ test/             # æµ‹è¯•é›†
â”œâ”€â”€ model_data/           # æ¨¡å‹é…ç½®æ–‡ä»¶
â”‚   â””â”€â”€ cls_classes.txt   # ç±»åˆ«æ ‡ç­¾æ–‡ä»¶
â”œâ”€â”€ models/               # ä¿å­˜çš„æ¨¡å‹æƒé‡
â”œâ”€â”€ logs/                 # è®­ç»ƒæ—¥å¿—å’Œæ£€æŸ¥ç‚¹
â”œâ”€â”€ metrics_out/          # è¯„ä¼°ç»“æœè¾“å‡º
â”œâ”€â”€ nets/                 # æ¨¡å‹æ¶æ„å®ç°
â”‚   â”œâ”€â”€ resnet.py
â”‚   â”œâ”€â”€ vgg.py
â”‚   â”œâ”€â”€ mobilenetv2.py
â”‚   â”œâ”€â”€ vision_transformer.py
â”‚   â”œâ”€â”€ swin_transformer.py
â”‚   â””â”€â”€ ...
â”œâ”€â”€ utils/                # å·¥å…·å‡½æ•°
â”‚   â”œâ”€â”€ dataloader.py     # æ•°æ®åŠ è½½å™¨
â”‚   â”œâ”€â”€ utils_fit.py      # è®­ç»ƒæµç¨‹
â”‚   â”œâ”€â”€ utils_metrics.py  # è¯„ä¼°æŒ‡æ ‡
â”‚   â”œâ”€â”€ callbacks.py      # å›è°ƒå‡½æ•°
â”‚   â””â”€â”€ early_stopping.py # æ—©åœå’Œæ£€æŸ¥ç‚¹
â”œâ”€â”€ train.py              # æ ‡å‡†è®­ç»ƒè„šæœ¬
â”œâ”€â”€ train_trimm.py        # timmæ¨¡å‹è®­ç»ƒè„šæœ¬
â”œâ”€â”€ eval.py               # æ¨¡å‹è¯„ä¼°è„šæœ¬
â”œâ”€â”€ predict.py            # å•å¼ å›¾ç‰‡æ¨ç†
â”œâ”€â”€ classification.py     # æ¨ç†å¼•æ“
â”œâ”€â”€ txt_annotation.py     # æ•°æ®é›†æ ‡æ³¨ç”Ÿæˆ
â””â”€â”€ requirements.txt      # ä¾èµ–æ¸…å•
```

---

## ğŸ“š è¯¦ç»†æ–‡æ¡£

### é…ç½®åŒæ­¥è¯´æ˜

**é‡è¦**: ä»¥ä¸‹å‚æ•°å¿…é¡»åœ¨å¤šä¸ªæ–‡ä»¶ä¸­ä¿æŒä¸€è‡´:

| å‚æ•° | train.py | classification.py | è¯´æ˜ |
|------|----------|-------------------|------|
| `backbone` | ç¬¬66è¡Œ | ç¬¬39è¡Œ | æ¨¡å‹æ¶æ„åç§° |
| `input_shape` | ç¬¬55è¡Œ | ç¬¬28è¡Œ | è¾“å…¥å›¾åƒå°ºå¯¸ |
| `model_path` | ç¬¬88è¡Œ | ç¬¬23è¡Œ | æƒé‡æ–‡ä»¶è·¯å¾„ |
| `classes_path` | ç¬¬51è¡Œ | ç¬¬24è¡Œ | ç±»åˆ«æ–‡ä»¶è·¯å¾„ |

### è®­ç»ƒç­–ç•¥è¯´æ˜

#### ä¸¤é˜¶æ®µè®­ç»ƒ

1. **é˜¶æ®µ1 - å†»ç»“ä¸»å¹²ç½‘ç»œ** (0-50è½®)
   - ä»…è®­ç»ƒåˆ†ç±»å¤´
   - å¤§æ‰¹é‡è®­ç»ƒ (batch_size=128)
   - å­¦ä¹ ç‡: 1e-3
   - ç›®çš„: å¿«é€Ÿé€‚åº”æ–°æ•°æ®é›†

2. **é˜¶æ®µ2 - è§£å†»å…¨éƒ¨ç½‘ç»œ** (50-300è½®)
   - è®­ç»ƒæ‰€æœ‰å±‚
   - å°æ‰¹é‡è®­ç»ƒ (batch_size=32)
   - å­¦ä¹ ç‡: 1e-4 (ä½™å¼¦è¡°å‡)
   - ç›®çš„: ç²¾ç»†è°ƒä¼˜

#### å­¦ä¹ ç‡è°ƒåº¦

æ”¯æŒä¸‰ç§ç­–ç•¥:
- `cos`: ä½™å¼¦é€€ç« (æ¨è)
- `step`: é˜¶æ¢¯å¼è¡°å‡
- `linear`: çº¿æ€§è¡°å‡

#### ä¼˜åŒ–å™¨é€‰æ‹©

```python
optimizer_type = "adam"  # æˆ– "sgd"
momentum = 0.9           # SGDåŠ¨é‡(ä»…SGD)
weight_decay = 0         # L2æ­£åˆ™åŒ–
```

### æ•°æ®å¢å¼º

æ”¯æŒå¤šç§å¢å¼ºç­–ç•¥:
- éšæœºè£å‰ªå’Œç¼©æ”¾
- éšæœºæ°´å¹³/å‚ç›´ç¿»è½¬
- é¢œè‰²æŠ–åŠ¨(äº®åº¦ã€å¯¹æ¯”åº¦ã€é¥±å’Œåº¦)
- éšæœºæ—‹è½¬
- Cutout/RandomErasing

é…ç½®ä½ç½®: `utils/dataloader.py`

### ç±»åˆ«ä¸å¹³è¡¡å¤„ç†

1. **Focal Loss**: è‡ªåŠ¨é™ä½æ˜“åˆ†ç±»æ ·æœ¬çš„æƒé‡
2. **ç±»åˆ«åŠ æƒ**: æ ¹æ®æ ·æœ¬æ•°é‡è‡ªåŠ¨è®¡ç®—æƒé‡
3. **å¹³è¡¡é‡‡æ ·**: ä¿è¯æ¯ä¸ªbatchç±»åˆ«åˆ†å¸ƒå‡è¡¡

### æ··åˆç²¾åº¦è®­ç»ƒ

```python
# train.pyä¸­å¯ç”¨
fp16 = True  # å‡å°‘50%æ˜¾å­˜,åŠ é€Ÿ1.5-2å€
```

è¦æ±‚: PyTorch >= 1.7.1

---

## ğŸ“Š è¯„ä¼°æŒ‡æ ‡

### åŸºç¡€æŒ‡æ ‡

- **Top-1 Accuracy**: æœ€é«˜é¢„æµ‹å‡†ç¡®ç‡
- **Top-5 Accuracy**: å‰5é¢„æµ‹å‡†ç¡®ç‡
- **Precision**: ç²¾ç¡®ç‡ (TP / (TP + FP))
- **Recall**: å¬å›ç‡ (TP / (TP + FN))
- **F1-Score**: ç²¾ç¡®ç‡å’Œå¬å›ç‡çš„è°ƒå’Œå¹³å‡

### é«˜çº§æŒ‡æ ‡

- **AUC**: å—è¯•è€…å·¥ä½œç‰¹å¾æ›²çº¿ä¸‹é¢ç§¯
  - Per-class AUC
  - Macro-AUC (ç±»åˆ«å¹³å‡)
  - Micro-AUC (æ ·æœ¬å¹³å‡)
- **Specificity**: ç‰¹å¼‚æ€§ (TN / (TN + FP))
- **Sensitivity**: æ•æ„Ÿæ€§ (ç­‰åŒäºRecall)
- **Bootstrap 95% ç½®ä¿¡åŒºé—´**: 1000æ¬¡é‡é‡‡æ ·ç»Ÿè®¡

### å¯è§†åŒ–è¾“å‡º

è¿è¡Œ `eval.py` å,å°†åœ¨ `metrics_out/` ç›®å½•ç”Ÿæˆ:

```
metrics_out/
â”œâ”€â”€ confusion_matrix.png              # æ··æ·†çŸ©é˜µçƒ­åŠ›å›¾
â”œâ”€â”€ confusion_matrix.csv              # æ··æ·†çŸ©é˜µCSV
â”œâ”€â”€ roc_curves.png                    # ROCæ›²çº¿(å«Macro/Microå¹³å‡)
â”œâ”€â”€ pr_curves.png                     # PRæ›²çº¿(å«Macro/Microå¹³å‡)
â”œâ”€â”€ confidence_intervals.png          # 6ä¸ªæŒ‡æ ‡çš„95%ç½®ä¿¡åŒºé—´
â”œâ”€â”€ metrics_comparison_chart.png      # æŒ‡æ ‡å¯¹æ¯”æŸ±çŠ¶å›¾
â”œâ”€â”€ Precision.png                     # å„ç±»åˆ«ç²¾ç¡®ç‡
â”œâ”€â”€ Recall.png                        # å„ç±»åˆ«å¬å›ç‡
â””â”€â”€ classification_report.txt         # å®Œæ•´åˆ†ç±»æŠ¥å‘Š(æ–‡æœ¬)
```

---

## â“ å¸¸è§é—®é¢˜

### 1. å½¢çŠ¶ä¸åŒ¹é…é”™è¯¯

**é—®é¢˜**: `RuntimeError: size mismatch`

**è§£å†³æ–¹æ¡ˆ**:
- æ£€æŸ¥ `input_shape` æ˜¯å¦ç¬¦åˆæ¨¡å‹è¦æ±‚(å¦‚Inceptionç³»åˆ—éœ€è¦299Ã—299)
- ç¡®è®¤ `cls_classes.txt` ä¸­çš„ç±»åˆ«æ•°é‡ä¸æ¨¡å‹åŒ¹é…
- éªŒè¯é¢„è®­ç»ƒæƒé‡ä¸ä¸»å¹²æ¶æ„å¯¹åº”

### 2. æ˜¾å­˜ä¸è¶³ (CUDA Out of Memory)

**è§£å†³æ–¹æ¡ˆ**:
```python
# æ–¹æ³•1: å‡å°æ‰¹é‡å¤§å°
batch_size = 16  # æˆ–æ›´å°

# æ–¹æ³•2: å¯ç”¨æ··åˆç²¾åº¦è®­ç»ƒ
fp16 = True

# æ–¹æ³•3: ä½¿ç”¨è½»é‡çº§æ¨¡å‹
backbone = 'mobilenetv2'
```

### 3. è®­ç»ƒä¸­æ–­åæ¢å¤

```python
# åœ¨train.pyä¸­è®¾ç½®
model_path = 'logs/ep050-loss0.123-val_loss0.456.pth'  # æ£€æŸ¥ç‚¹è·¯å¾„
Init_Epoch = 50  # ä»ç¬¬50è½®æ¢å¤
Freeze_Epoch = 50  # å·²å®Œæˆå†»ç»“è®­ç»ƒ
```

### 4. å¦‚ä½•ä½¿ç”¨è‡ªå®šä¹‰æ•°æ®é›†?

1. æŒ‰ [å¿«é€Ÿå¼€å§‹](#å¿«é€Ÿå¼€å§‹) ä¸­çš„ç›®å½•ç»“æ„ç»„ç»‡æ•°æ®
2. è¿è¡Œ `txt_annotation.py` ç”Ÿæˆæ ‡æ³¨
3. ä¿®æ”¹ `train.py` ä¸­çš„ `classes_path` å’Œç±»åˆ«æ•°é‡
4. å¼€å§‹è®­ç»ƒ

### 5. å¤šGPUè®­ç»ƒæ”¯æŒå—?

**æ”¯æŒ**, ä½†ç›®å‰ä»…åœ¨Linuxç³»ç»Ÿæµ‹è¯•:

```bash
# DataParallelæ¨¡å¼
CUDA_VISIBLE_DEVICES=0,1 python train.py

# DistributedDataParallelæ¨¡å¼(æ¨è)
CUDA_VISIBLE_DEVICES=0,1 python -m torch.distributed.launch \
    --nproc_per_node=2 train.py
```

### 6. å¦‚ä½•å¯¼å‡ºä¸ºONNX?

```python
import torch

model = ...  # åŠ è½½ä½ çš„æ¨¡å‹
model.eval()

dummy_input = torch.randn(1, 3, 224, 224)
torch.onnx.export(
    model,
    dummy_input,
    "model.onnx",
    opset_version=11,
    input_names=['input'],
    output_names=['output']
)
```

## ğŸ“„ è®¸å¯è¯

æœ¬é¡¹ç›®é‡‡ç”¨ [MIT License](LICENSE) å¼€æºåè®®ã€‚

---

## ğŸ™ è‡´è°¢

- [PyTorch](https://pytorch.org/) - æ·±åº¦å­¦ä¹ æ¡†æ¶
- [timm](https://github.com/huggingface/pytorch-image-models) - é¢„è®­ç»ƒæ¨¡å‹åº“
- [scikit-learn](https://scikit-learn.org/) - è¯„ä¼°æŒ‡æ ‡å·¥å…·

---


<div align="center">

**å¦‚æœè¿™ä¸ªé¡¹ç›®å¯¹ä½ æœ‰å¸®åŠ©,è¯·ç»™ä¸€ä¸ªâ­Staræ”¯æŒä¸€ä¸‹!**

Made with â¤ï¸ by [wuxb55]

</div>
